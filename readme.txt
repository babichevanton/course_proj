Схема работы:
1) Из JSON-файла "data/models.json" в класс DataStore закачиваются данные для обучения классификатоов и создания множества элементарных исходов
2) Из файла "data/posts.txt" в папке "data" идет загрузка постов.
3) Если в папке "data" отсутствуют файлы моделей классификаторов, то обделенный(ые) классификатор(ы) обучается, иначе загружает модель из файла
4) Загружается множество элементарных исходов из DataStore
5) Далее для каждого загруженного поста
5.1) Вызывается метод sequential_covering класса BlockingSchemeLearner, осуществляющий предобработку множества элементарных исходов. На выходе правило в виде ДНФ
5.2) Вызывается метод getCandidates класса BlockingSchemeLearner, возвращающий все элементы, удовлетворяющие правилу - подмножество множества элементарных исходов
5.3) Вызывается метод svm_predict класса PostExplorer, возвращающий массив вероятностей отнесения поста к каждому из кандидатов.
5.4) Вызывается метод results класса PostExplorer, размечающий пост и осуществляющий чистку атрибутов. Результаты дозаписываются в файл "res.txt". В начале работы программы файл удаляется, если существует.

Для проверки точности используется файл разметки "data/data.txt", файл с результатами "res.txt" и скрипт проверки process.py 

1) Запустить скрипт проверки командой "python process.py"
2) В консоль будут выведены значения точности, полноты и f1-меры для каждого из атрибутов, а также в среднем по всем 6 атрибутам.
